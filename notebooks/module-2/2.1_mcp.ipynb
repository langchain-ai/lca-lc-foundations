{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "717edf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61d94437-7393-45ae-8e66-453474c59570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import asyncio\n",
    "\n",
    "# Fix for Windows issues in Jupyter notebooks\n",
    "if sys.platform == \"win32\":\n",
    "    # 1. Use ProactorEventLoop for subprocess support\n",
    "    if not isinstance(asyncio.get_event_loop_policy(), asyncio.WindowsProactorEventLoopPolicy):\n",
    "        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "    \n",
    "    # 2. Redirect stderr to avoid fileno() error when launching MCP servers\n",
    "    if \"ipykernel\" in sys.modules:\n",
    "        sys.stderr = sys.__stderr__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d701224",
   "metadata": {},
   "source": [
    "## Local MCP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f11678d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"local_server\": {\n",
    "                \"transport\": \"stdio\",\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"resources/2.1_mcp_server.py\"],\n",
    "            }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "184db1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tools\n",
    "tools = await client.get_tools()\n",
    "\n",
    "# get resources\n",
    "resources = await client.get_resources(\"local_server\")\n",
    "\n",
    "# get prompts\n",
    "prompt = await client.get_prompt(\"local_server\", \"prompt\")\n",
    "prompt = prompt[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d548fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=tools,\n",
    "    system_prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5256ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = await agent.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Tell me about the langchain-mcp-adapters library\")]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3efb5bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Tell me about the langchain-mcp-adapters library', additional_kwargs={}, response_metadata={}, id='54ca3831-d360-4b73-86a9-7b6248ab4338'),\n",
      "              AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 271, 'total_tokens': 364, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cp25FNKINhf4fbI5DVR2AhKudvneN', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b3e6b-38b3-7733-9a47-999c635ff459-0', tool_calls=[{'name': 'search_web', 'args': {'query': 'langchain-mcp-adapters library'}, 'id': 'call_mmDmhw4rGgdStpmpGMcRVHR4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 271, 'output_tokens': 93, 'total_tokens': 364, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}),\n",
      "              ToolMessage(content=[{'type': 'text', 'text': '{\\n  \"query\": \"langchain-mcp-adapters library\",\\n  \"follow_up_questions\": null,\\n  \"answer\": null,\\n  \"images\": [],\\n  \"results\": [\\n    {\\n      \"url\": \"https://github.com/langchain-ai/langchainjs-mcp-adapters\",\\n      \"title\": \"GitHub - langchain-ai/langchainjs-mcp-adapters: ** THIS ...\",\\n      \"content\": \"# Search code, repositories, users, issues, pull requests... You signed in with another tab or window. You signed out in another tab or window. You switched accounts on another tab or window. langchain-ai   /  **langchainjs-mcp-adapters**  Public archive. \\\\\\\\*\\\\\\\\* THIS REPO HAS MOVED TO  \\\\\\\\*\\\\\\\\* Adapters for integrating Model Context Protocol (MCP) tools with LangChain.js applications, supporting both stdio and SSE transports. 245 stars   34 forks   Branches   Tags   Activity. # langchain-ai/langchainjs-mcp-adapters. | RELEASE\\\\\\\\_NOTES.md | RELEASE\\\\\\\\_NOTES.md |  |  |. | tsconfig.cjs.json | tsconfig.cjs.json |  |  |. | tsconfig.examples.json | tsconfig.examples.json |  |  |. | tsconfig.tests.json | tsconfig.tests.json |  |  |. ## Repository files navigation. # LangChain.js MCP Adapters. This library provides a lightweight wrapper to allow Model Context Protocol (MCP) services to be used with LangChain.js. \\\\\\\\*\\\\\\\\* THIS REPO HAS MOVED TO  \\\\\\\\*\\\\\\\\* Adapters for integrating Model Context Protocol (MCP) tools with LangChain.js applications, supporting both stdio and SSE transports. javascript   typescript   mcp   ai-tools   langchain   llm-tools   openai-functions   langchainjs   llm-agents   agent-tools   llm-integration   model-context-protocol.\",\\n      \"score\": 0.8868231,\\n      \"raw_content\": null\\n    },\\n    {\\n      \"url\": \"https://medium.com/@deepakkamboj/the-complete-guide-to-langchain-mcp-adapters-bridging-langchain-and-model-context-protocol-3f5507cbd3ca\",\\n      \"title\": \"The Complete Guide to langchain-mcp-adapters\",\\n      \"content\": \"The langchain-mcp-adapters library serves three primary functions: Tool Conversion: Automatically converts MCP tools into LangChain and ...Read more\",\\n      \"score\": 0.88178825,\\n      \"raw_content\": null\\n    },\\n    {\\n      \"url\": \"https://pypi.org/project/langchain-mcp-adapters/\",\\n      \"title\": \"langchain-mcp-adapters\",\\n      \"content\": \"This library provides a lightweight wrapper that makes Anthropic Model Context Protocol (MCP) tools compatible with LangChain and LangGraph.Read more\",\\n      \"score\": 0.8775715,\\n      \"raw_content\": null\\n    },\\n    {\\n      \"url\": \"https://changelog.langchain.com/announcements/mcp-adapters-for-langchain-and-langgraph\",\\n      \"title\": \"MCP Adapters for LangChain and LangGraph\",\\n      \"content\": \"# LangChain Changelog. Sign up for our newsletter to stay up to date. # MCP Adapters for LangChain and LangGraph. The **LangChain MCP Adapters** is a package that makes it easy to use **Anthropic Model Context Protocol (MCP) tools** with LangChain & LangGraph. * Converts **MCP tools** into **LangChain- & LangGraph-compatible tools**. * Enables interaction with tools across multiple **MCP servers**. * Seamlessly integrates the **hundreds of tool servers** already published into LangGraph Agents. ### Why use MCP Adapters:. This adapter makes it simple to connect LangChain and LangGraph with the growing ecosystem of MCP tool servers. Instead of manually adapting each tool, you can now integrate them seamlessly. It also allows agents to pull from multiple MCP servers at once, making it easier to combine different tools for more powerful applications. MCP is gaining serious traction, and this adapter helps LangGraph agents take full advantage. ##### Subscribe to updates.\",\\n      \"score\": 0.87139857,\\n      \"raw_content\": null\\n    },\\n    {\\n      \"url\": \"https://docs.langchain.com/oss/python/langchain/mcp\",\\n      \"title\": \"Model Context Protocol (MCP) - Docs by LangChain\",\\n      \"content\": \"The langchain-mcp-adapters library uses the official MCP SDK under the hood, which allows you to provide a custom authentication mechanism by implementing the ...Read more\",\\n      \"score\": 0.8565368,\\n      \"raw_content\": null\\n    }\\n  ],\\n  \"response_time\": 0.83,\\n  \"request_id\": \"df8c0ab3-993d-499e-bacb-c5593e24e08f\"\\n}', 'id': 'lc_4c815fbe-bfed-4949-a4ba-065959a7b804'}], name='search_web', id='2ef65eaf-5550-4598-aa7b-a92c695068a2', tool_call_id='call_mmDmhw4rGgdStpmpGMcRVHR4', artifact={'structured_content': {'result': {'query': 'langchain-mcp-adapters library', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://github.com/langchain-ai/langchainjs-mcp-adapters', 'title': 'GitHub - langchain-ai/langchainjs-mcp-adapters: ** THIS ...', 'content': '# Search code, repositories, users, issues, pull requests... You signed in with another tab or window. You signed out in another tab or window. You switched accounts on another tab or window. langchain-ai   /  **langchainjs-mcp-adapters**  Public archive. \\\\*\\\\* THIS REPO HAS MOVED TO  \\\\*\\\\* Adapters for integrating Model Context Protocol (MCP) tools with LangChain.js applications, supporting both stdio and SSE transports. 245 stars   34 forks   Branches   Tags   Activity. # langchain-ai/langchainjs-mcp-adapters. | RELEASE\\\\_NOTES.md | RELEASE\\\\_NOTES.md |  |  |. | tsconfig.cjs.json | tsconfig.cjs.json |  |  |. | tsconfig.examples.json | tsconfig.examples.json |  |  |. | tsconfig.tests.json | tsconfig.tests.json |  |  |. ## Repository files navigation. # LangChain.js MCP Adapters. This library provides a lightweight wrapper to allow Model Context Protocol (MCP) services to be used with LangChain.js. \\\\*\\\\* THIS REPO HAS MOVED TO  \\\\*\\\\* Adapters for integrating Model Context Protocol (MCP) tools with LangChain.js applications, supporting both stdio and SSE transports. javascript   typescript   mcp   ai-tools   langchain   llm-tools   openai-functions   langchainjs   llm-agents   agent-tools   llm-integration   model-context-protocol.', 'score': 0.8868231, 'raw_content': None}, {'url': 'https://medium.com/@deepakkamboj/the-complete-guide-to-langchain-mcp-adapters-bridging-langchain-and-model-context-protocol-3f5507cbd3ca', 'title': 'The Complete Guide to langchain-mcp-adapters', 'content': 'The langchain-mcp-adapters library serves three primary functions: Tool Conversion: Automatically converts MCP tools into LangChain and ...Read more', 'score': 0.88178825, 'raw_content': None}, {'url': 'https://pypi.org/project/langchain-mcp-adapters/', 'title': 'langchain-mcp-adapters', 'content': 'This library provides a lightweight wrapper that makes Anthropic Model Context Protocol (MCP) tools compatible with LangChain and LangGraph.Read more', 'score': 0.8775715, 'raw_content': None}, {'url': 'https://changelog.langchain.com/announcements/mcp-adapters-for-langchain-and-langgraph', 'title': 'MCP Adapters for LangChain and LangGraph', 'content': '# LangChain Changelog. Sign up for our newsletter to stay up to date. # MCP Adapters for LangChain and LangGraph. The **LangChain MCP Adapters** is a package that makes it easy to use **Anthropic Model Context Protocol (MCP) tools** with LangChain & LangGraph. * Converts **MCP tools** into **LangChain- & LangGraph-compatible tools**. * Enables interaction with tools across multiple **MCP servers**. * Seamlessly integrates the **hundreds of tool servers** already published into LangGraph Agents. ### Why use MCP Adapters:. This adapter makes it simple to connect LangChain and LangGraph with the growing ecosystem of MCP tool servers. Instead of manually adapting each tool, you can now integrate them seamlessly. It also allows agents to pull from multiple MCP servers at once, making it easier to combine different tools for more powerful applications. MCP is gaining serious traction, and this adapter helps LangGraph agents take full advantage. ##### Subscribe to updates.', 'score': 0.87139857, 'raw_content': None}, {'url': 'https://docs.langchain.com/oss/python/langchain/mcp', 'title': 'Model Context Protocol (MCP) - Docs by LangChain', 'content': 'The langchain-mcp-adapters library uses the official MCP SDK under the hood, which allows you to provide a custom authentication mechanism by implementing the ...Read more', 'score': 0.8565368, 'raw_content': None}], 'response_time': 0.83, 'request_id': 'df8c0ab3-993d-499e-bacb-c5593e24e08f'}}}),\n",
      "              AIMessage(content='Here’s a concise overview of the langchain-mcp-adapters family and how it fits with LangChain, LangGraph, and MCP (Model Context Protocol).\\n\\nWhat it is\\n- A library that makes Anthropic’s Model Context Protocol (MCP) tools usable inside LangChain and LangGraph workflows.\\n- It acts as a bridge: MCP tools (tools hosted on MCP servers) get converted into LangChain/LangGraph–compatible tools that can be consumed by LangChain.js or LangChain (Python) pipelines.\\n- It enables using MCP tool servers across multiple MCP servers at once, which makes it easy to combine tools from different providers or environments.\\n\\nTwo main implementations (by language)\\n- Python version: langchain-mcp-adapters\\n  - Published on PyPI and intended for use with LangChain (Python) and LangGraph.\\n  - Uses the official MCP SDK under the hood and supports custom authentication mechanisms implemented via that SDK.\\n  - Link: PyPI page for langchain-mcp-adapters.\\n- JavaScript/TypeScript version (LangChain.js ecosystem)\\n  - Repository commonly referred to as langchainjs-mcp-adapters (GitHub).\\n  - Provides adapters to wrap MCP tools so they can be used with LangChain.js apps and LangGraph.\\n  - Note: This repo has moved or been superseded by a newer “Adapters” package in the LangChain org; the repo description notes the move and points to the new adapters repository for LangChain.js MCP adapters.\\n  - Link: GitHub repo for langchainjs-mcp-adapters (and related note about the move to the adapters package).\\n\\nKey features\\n- Tool conversion: MCP tools are converted into LangChain- and LangGraph-compatible tools so you can use MCP-hosted tools with LangChain agents, chains, and workflows.\\n- Multi-server support: You can interact with tools from multiple MCP servers in a single LangChain/LangGraph workflow.\\n- Transports: Supports both stdio and SSE transports for MCP communications, enabling flexible deployment scenarios (e.g., running MCP servers as separate processes or via server-sent events).\\n- Authentication and SDK: Uses the official MCP SDK under the hood, allowing custom authentication setups as provided by MCP.\\n\\nWhere to read more\\n- Documentation: LangChain’s MCP docs discuss how the langchain-mcp-adapters library uses the MCP SDK and how to authenticate and configure MCP tools.\\n  - Model Context Protocol (MCP) - Docs by LangChain\\n- Changes and rationale:\\n  - MCP Adapters for LangChain and LangGraph (LangChain changelog) — explains the purpose of the adapters and how they integrate MCP tool servers with LangChain/LangGraph.\\n- Community guides and overviews:\\n  - The Complete Guide to langchain-mcp-adapters (Medium) — a narrative guide covering use cases like tool conversion, multi-server access, and integration patterns.\\n- Package pages:\\n  - langchain-mcp-adapters (Python, PyPI) — Python installation and usage notes.\\n  - langchainjs-mcp-adapters (GitHub) — JavaScript/TypeScript adapter repository (note about the move to the “Adapters” package).\\n\\nUsage overview (high level)\\n- Python:\\n  - Install: pip install langchain-mcp-adapters\\n  - Create an MCP client/config with your MCP servers and credentials (using the MCP SDK under the hood).\\n  - Wrap MCP tools with the adapter so they appear as LangChain Tools.\\n  - Use these tools in LangChain Python workflows, e.g., with Tools, Agents, or Chains, just like you would with native LangChain tools.\\n- JavaScript/TypeScript:\\n  - Install the JS package (e.g., langchainjs-mcp-adapters or the corresponding npm package name) and set up MCP server access.\\n  - Convert MCP tools to LangChain.js tools and use them in Agents/Chains within LangChain.js projects.\\n  - Leverage multi-server access and transports (stdio/SSE) as needed for your deployment.\\n\\nIf you’d like, I can:\\n- Point you to a quick-start for Python or JavaScript with minimal code.\\n- Look up the exact installation commands and a tiny example from the official docs.\\n- Help you decide which language version to use based on your project (Python vs. JS, LangChain vs. LangGraph, etc.).\\n\\nWould you like a language-specific quick-start (Python or JavaScript) or a deeper dive into the MCP adapters’ API surface?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3863, 'prompt_tokens': 1347, 'total_tokens': 5210, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 2944, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cp25Hzp2kQZkK3dMd1zS6CCpNuAnZ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b3e6b-43d9-7502-924d-fa99a0cd4bbb-0', usage_metadata={'input_tokens': 1347, 'output_tokens': 3863, 'total_tokens': 5210, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 2944}})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847409a3",
   "metadata": {},
   "source": [
    "## Online MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2895fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"time\": {\n",
    "            \"transport\": \"stdio\",\n",
    "            \"command\": \"uvx\",\n",
    "            \"args\": [\n",
    "                \"mcp-server-time\",\n",
    "                \"--local-timezone=America/New_York\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "tools = await client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e264dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"gpt-5-nano\",\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4725cee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What time is it?', additional_kwargs={}, response_metadata={}, id='5cff5789-2fae-4f52-b4b5-dd2baa744941'),\n",
      "              AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 155, 'prompt_tokens': 296, 'total_tokens': 451, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 128, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cp25jkZtPAq1HyuGIEkz8ue7Rw7JR', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b3e6b-ade8-7441-b478-b5985ecb1713-0', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'America/New_York'}, 'id': 'call_OPinoYPWFKAio53U4LhAuBjW', 'type': 'tool_call'}], usage_metadata={'input_tokens': 296, 'output_tokens': 155, 'total_tokens': 451, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 128}}),\n",
      "              ToolMessage(content=[{'type': 'text', 'text': '{\\n  \"timezone\": \"America/New_York\",\\n  \"datetime\": \"2025-12-20T20:00:05-05:00\",\\n  \"day_of_week\": \"Saturday\",\\n  \"is_dst\": false\\n}', 'id': 'lc_4697f242-a2ab-4d4f-9100-2f7e45b6fe42'}], name='get_current_time', id='2499e243-7ead-41f9-9f61-ca548364cf77', tool_call_id='call_OPinoYPWFKAio53U4LhAuBjW'),\n",
      "              AIMessage(content=\"It's 8:00:05 PM on Saturday, December 20, 2025 in New York (Eastern Standard Time, UTC−5). Want me to convert to another timezone?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 495, 'prompt_tokens': 379, 'total_tokens': 874, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 448, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-Cp25lEICHVQGXoTXOAacCrSYwGP0D', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b3e6b-b69a-7ed0-b30d-2231b34d5511-0', usage_metadata={'input_tokens': 379, 'output_tokens': 495, 'total_tokens': 874, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 448}})]}\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessage(content=\"What time is it?\")\n",
    "\n",
    "response = await agent.ainvoke(\n",
    "    {\"messages\": [question]}\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc5152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
